{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0ec6b2485cc52f156241b896df895903b4e291e0f092ffc6896f23880fb640eba",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# \"Notes about `multiprocessing` in Python\"\n",
    "\n",
    "- toc: false\n",
    "- badges: true\n",
    "- categories: [coding, python, parallelism, thread, process]\n",
    "- comments: true"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## GIL, threading, multiprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "GIL (Global Interpreter Lock) assures that only one thread executes Python bytecode in a process at a time. Therefore, multithreading program achieved by the `threading` module cannot fully utilize multi-core manchines. To write a parallel program in Python, the `multiprocessing` module should be used.\n",
    "\n",
    "> Since GIL is always released when doing I/O, `threading` is still an appropriate module if we want to run multiple I/O-bound tasks simultaneously.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Process"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "It is quite easy to create a new process in Python. We basically pass a target function and all arguments needed by the invocation to the `Process` object. Use `start()` to start the process's activity (i.e. the invocation of the target function). Use `join()` to block the parent process until the child process exits."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Start sleeping for 2 seconds...\n",
      "before join(), the parent process is not blocked\n",
      "Sleeping ends.\n",
      "Hello, world.\n",
      "After join()\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "import time\n",
    "\n",
    "def worker(s):\n",
    "    print('Start sleeping for 2 seconds...')\n",
    "    time.sleep(2)\n",
    "    print('Sleeping ends.')\n",
    "    print(s)\n",
    "\n",
    "p = Process(target=worker, args=('Hello, world.',))\n",
    "p.start()\n",
    "print('before join(), the parent process is not blocked')\n",
    "p.join()\n",
    "print('After join()')"
   ]
  },
  {
   "source": [
    "If an exception happens in the child process, the stack trace will also be printed in the console."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Process Process-99:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-27-8d12741476dc>\", line 5, in worker\n",
      "    print(2 / 0)\n",
      "ZeroDivisionError: division by zero\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "import time\n",
    "\n",
    "def worker(s):\n",
    "    print(2 / 0)\n",
    "\n",
    "p = Process(target=worker, args=('Hello, world.',))\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "source": [
    "## Process Pool"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We can also create a pool of processes. The following snippet creates a process pool of size 4, and we put 8 tasks into the pool."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "4\n",
      "2\n",
      "3\n",
      "1\n",
      "7\n",
      "6\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import time\n",
    "import random\n",
    "\n",
    "def worker(i):\n",
    "    time.sleep(random.random())\n",
    "    print(i)\n",
    "\n",
    "p = Pool(4)\n",
    "for i in range(8):\n",
    "    p.apply_async(worker, args=(i,))\n",
    "p.close()\n",
    "p.join()"
   ]
  },
  {
   "source": [
    "When invoking `apply_async()`, a new task is submitted to the pool and the task will start once there is an empty slot in the pool. `Pool` also has a synchronized version of this method, `apply()`, which will block the parent process until the result is ready. Therefore, for parallelism, `apply_async()` should always be used. We also used `join()` method to block the parent process after we finished adding all tasks to the pool. If we do not block the parent process, **parent process might exit before child processes finish their tasks**. That's why we always use `join()` in the parent process to avoid this situation. Note that `close()` must be called before using `join()`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Unlike `Process`, stack trace of exceptions in `Pool` will not be printed in the console, but we might need that when debugging a multiprocessing program. We can pass an error callback function to the `apply_async()` method, and that function will be used to print stack trace if exceptions happen. Note that the callback functions will block the parent process, so, do not put time-consuming tasks in the callback function since it should complete immediately. The error callback function only takes one argument and that is the exception instance."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n",
      "None\n",
      "multiprocessing.pool.RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-50-90874a7b31e2>\", line 5, in worker\n",
      "    print(i / 0)\n",
      "ZeroDivisionError: division by zero\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "ZeroDivisionError: division by zero\n",
      "multiprocessing.pool.RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-50-90874a7b31e2>\", line 5, in worker\n",
      "    print(i / 0)\n",
      "ZeroDivisionError: division by zero\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "ZeroDivisionError: division by zero\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import traceback\n",
    "\n",
    "def worker(i):\n",
    "    print(i / 0)\n",
    "\n",
    "def print_traceback(e):\n",
    "    print(traceback.print_exception(type(e), e, e.__traceback__))\n",
    "\n",
    "p = Pool(1)\n",
    "for i in range(2):\n",
    "    p.apply_async(worker, args=(i,), error_callback=print_traceback)\n",
    "p.close()\n",
    "p.join()"
   ]
  },
  {
   "source": [
    "## Communication Between Processes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "I usually just use `Queue` for communication between processes, even if there are only two processes, in which `Pipe` also works. We don't have to worry about race conditions when using queue since queues are **thread and process safe** in Python. We will look at the one-producer-one-consumer case first."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "producer exits4\n",
      "\n",
      "consumer exits\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "import time, random\n",
    "\n",
    "def producer(q):\n",
    "    for i in range(5):\n",
    "        time.sleep(random.random())\n",
    "        q.put(i)\n",
    "    q.put('end') # to notify the consumer process that the producer process has exited\n",
    "    print('producer exits')\n",
    "\n",
    "def consumer(q):\n",
    "    while True:\n",
    "        product = q.get()\n",
    "        if product == 'end':\n",
    "            break\n",
    "        print(product)\n",
    "    print('consumer exits')\n",
    "\n",
    "q = Queue()\n",
    "p1 = Process(target=producer, args=(q,))\n",
    "p2 = Process(target=consumer, args=(q,))\n",
    "p1.start()\n",
    "p2.start()\n",
    "p1.join()\n",
    "p2.join()"
   ]
  },
  {
   "source": [
    "There might be race conditions on invocations of `print()`, so multiple lines could be shown in the same line. But other than that, everything should be expected. Note that the `get()` method of `Queue` will block the child process if no item in the queue is immediately available. We can avoid blocking by set argument `block` to `Fasle` or simply using `get_nowait()`, but it will raise an exception if it cannot get an item immediately. If we want to avoid blocking for too long, we can pass a `timeout` argument to `get()`. If the size of a queue is limited, the same approach can also be applied to the `put()` method."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We now look at the multi-producer-multi-consumer case, where we will use `Pool`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 537, in _handle_tasks\n",
      "    put(task)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 58, in __getstate__\n",
      "    context.assert_spawning(self)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/context.py\", line 359, in assert_spawning\n",
      "    raise RuntimeError(\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 537, in _handle_tasks\n",
      "    put(task)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 58, in __getstate__\n",
      "    context.assert_spawning(self)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/context.py\", line 359, in assert_spawning\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Queue objects should only be shared between processes through inheritance\n",
      "RuntimeError: Queue objects should only be shared between processes through inheritance\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 537, in _handle_tasks\n",
      "    put(task)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 58, in __getstate__\n",
      "    context.assert_spawning(self)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/context.py\", line 359, in assert_spawning\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Queue objects should only be shared between processes through inheritance\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 537, in _handle_tasks\n",
      "    put(task)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 58, in __getstate__\n",
      "    context.assert_spawning(self)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/context.py\", line 359, in assert_spawning\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Queue objects should only be shared between processes through inheritance\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, Queue\n",
    "import time, random\n",
    "\n",
    "def print_traceback(e):\n",
    "    print(traceback.print_exception(type(e), e, e.__traceback__))\n",
    "\n",
    "def producer(q, producer_id):\n",
    "    for i in range(5):\n",
    "        time.sleep(random.random())\n",
    "        q.put(f'product {i} from producer {producer_id}')\n",
    "    q.put('end') # to notify the consumer process that the producer process has exited\n",
    "    print(f'producer {producer_id} exits')\n",
    "\n",
    "def consumer(q, consumer_id):\n",
    "    while True:\n",
    "        product = q.get()\n",
    "        if product == 'end':\n",
    "            break\n",
    "        print(f'{product} consumed by consumer {consumer_id}')\n",
    "    print(f'consumer {consumer_id} exits')\n",
    "\n",
    "q = Queue()\n",
    "producer_count = 2\n",
    "consumer_count = 2\n",
    "producer_pool = Pool(producer_count)\n",
    "consumer_pool = Pool(consumer_count)\n",
    "for i in range(producer_count):\n",
    "    producer_pool.apply_async(producer, args=(q, i), error_callback=print_traceback)\n",
    "for i in range(consumer_count):\n",
    "    consumer_pool.apply_async(consumer, args=(q, i), error_callback=print_traceback)\n",
    "producer_pool.close()\n",
    "consumer_pool.close()\n",
    "producer_pool.join()\n",
    "consumer_pool.join()"
   ]
  },
  {
   "source": [
    "We are getting `RuntimeError`, and it says `Queue objects should only be shared between processes through inheritance`. This happens if we try to use `multiprocessing.Queue` in a process pool. As for solution, we should use `multiprocessing.Manager.Queue` among pool workers instead."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "product 0 from producer 1 consumed by consumer 0\n",
      "product 0 from producer 0 consumed by consumer 1\n",
      "product 1 from producer 1 consumed by consumer 0\n",
      "product 1 from producer 0 consumed by consumer 1\n",
      "product 2 from producer 0 consumed by consumer 0\n",
      "product 2 from producer 1 consumed by consumer 1\n",
      "product 3 from producer 0 consumed by consumer 0\n",
      "product 3 from producer 1 consumed by consumer 1\n",
      "consumer 1 exitsproduct 4 from producer 1 consumed by consumer 0\n",
      "\n",
      "producer 1 exits\n",
      "product 4 from producer 0 consumed by consumer 0\n",
      "producer 0 exitsconsumer 0 exits\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, Manager\n",
    "import time, random\n",
    "\n",
    "def print_traceback(e):\n",
    "    print(traceback.print_exception(type(e), e, e.__traceback__))\n",
    "\n",
    "def producer(q, producer_id):\n",
    "    for i in range(5):\n",
    "        time.sleep(random.random())\n",
    "        q.put(f'product {i} from producer {producer_id}')\n",
    "    q.put('end') # to notify the consumer process that a producer process has exited\n",
    "    print(f'producer {producer_id} exits')\n",
    "\n",
    "def consumer(q, consumer_id):\n",
    "    while True:\n",
    "        product = q.get()\n",
    "        if product == 'end':\n",
    "            break\n",
    "        print(f'{product} consumed by consumer {consumer_id}')\n",
    "    print(f'consumer {consumer_id} exits')\n",
    "\n",
    "manager = Manager()\n",
    "q = manager.Queue()\n",
    "producer_count = 2\n",
    "consumer_count = 2\n",
    "producer_pool = Pool(producer_count)\n",
    "consumer_pool = Pool(consumer_count)\n",
    "for i in range(producer_count):\n",
    "    producer_pool.apply_async(producer, args=(q, i), error_callback=print_traceback)\n",
    "for i in range(consumer_count):\n",
    "    consumer_pool.apply_async(consumer, args=(q, i), error_callback=print_traceback)\n",
    "producer_pool.close()\n",
    "consumer_pool.close()\n",
    "producer_pool.join()\n",
    "consumer_pool.join()"
   ]
  },
  {
   "source": [
    "## Lock"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The above snippet has several flaws. Firstly, invocations of `print()` in different processes has race conditions, which could mess up the printed text in the console. Also, a consumer exits immediately when it receives an `end` signal, which is not desired since there might be products from one producer enqueued after the `end` signal from another producer. We want consumers to exit only if all producers have exited.\n",
    "\n",
    "To handle the `print()` problem, we need a lock to avoid race conditions. To know whether all producers have exited or not, we need a shared value among consumers, which counts the number of exited producers. This shared value will be increased by 1 every time a consumer receives an `end` signal."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "product 0 from producer 1 consumed by consumer 0\n",
      "product 0 from producer 0 consumed by consumer 0\n",
      "product 1 from producer 1 consumed by consumer 0\n",
      "product 2 from producer 1 consumed by consumer 1\n",
      "product 1 from producer 0 consumed by consumer 0\n",
      "product 3 from producer 1 consumed by consumer 0\n",
      "product 2 from producer 0 consumed by consumer 0\n",
      "product 4 from producer 1 consumed by consumer 0\n",
      "producer 1 exits\n",
      "product 3 from producer 0 consumed by consumer 1\n",
      "producer 0 exits\n",
      "product 4 from producer 0 consumed by consumer 0\n",
      "consumer 1 exits\n",
      "consumer 0 exits\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, Manager, Value\n",
    "import time, random\n",
    "\n",
    "def print_traceback(e):\n",
    "    print(traceback.print_exception(type(e), e, e.__traceback__))\n",
    "\n",
    "def producer(q, producer_id, print_lock):\n",
    "    for i in range(5):\n",
    "        time.sleep(random.random())\n",
    "        q.put(f'product {i} from producer {producer_id}')\n",
    "    q.put('end') # to notify the consumer process that a producer process has exited\n",
    "    with print_lock:\n",
    "        print(f'producer {producer_id} exits')\n",
    "\n",
    "def consumer(q, consumer_id, producer_count, print_lock, exited_producer_count, count_lock):\n",
    "    while True:\n",
    "        try:\n",
    "            product = q.get_nowait()\n",
    "        except:\n",
    "            if exited_producer_count.value == producer_count:\n",
    "                # all producers have exited\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "        if product == 'end':\n",
    "            with count_lock:\n",
    "                exited_producer_count.value += 1\n",
    "            continue\n",
    "        with print_lock:\n",
    "            print(f'{product} consumed by consumer {consumer_id}')\n",
    "    with print_lock:\n",
    "        print(f'consumer {consumer_id} exits')\n",
    "\n",
    "manager = Manager()\n",
    "q = manager.Queue()\n",
    "exited_producer_count = manager.Value('i', 0) # type code 'i' means 'signed int' in C type\n",
    "print_lock = manager.Lock()\n",
    "count_lock = manager.Lock()\n",
    "producer_count = 2\n",
    "consumer_count = 2\n",
    "producer_pool = Pool(producer_count)\n",
    "consumer_pool = Pool(consumer_count)\n",
    "for i in range(producer_count):\n",
    "    producer_pool.apply_async(producer, args=(q, i, print_lock), error_callback=print_traceback)\n",
    "for i in range(consumer_count):\n",
    "    consumer_pool.apply_async(consumer, args=(q, i, producer_count, print_lock, exited_producer_count, count_lock), error_callback=print_traceback)\n",
    "producer_pool.close()\n",
    "consumer_pool.close()\n",
    "producer_pool.join()\n",
    "consumer_pool.join()"
   ]
  },
  {
   "source": [
    "We defined two locks. The `print_lock` is acquired before each `print()` invocation. Another lock `count_lock` ensures that the increment of `exited_producer_count` is atomic. Same as `Queue`, we have to use `multiprocessing.Manager.Value` instead of `multiprocessing.Value` in a process pool. As shown in the output, each `print()` invocation takes one line exclusively, and consumers exited only if all producers have exited.\n",
    "\n",
    "The following snipppet will demonstrate race conditions between processes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Manager, Pool, Value\n",
    "\n",
    "def print_traceback(e):\n",
    "    print(traceback.print_exception(type(e), e, e.__traceback__))\n",
    "\n",
    "def add(counter):\n",
    "    for _ in range(100):\n",
    "        counter.value += 1\n",
    "\n",
    "def sub(counter):\n",
    "    for _ in range(100):\n",
    "        counter.value -= 1\n",
    "\n",
    "manager = Manager()\n",
    "counter = manager.Value('i', 0)\n",
    "add_pool = Pool(4)\n",
    "add_pool.starmap_async(add, [(counter,) for _ in range(4)], error_callback=print_traceback)\n",
    "sub_pool = Pool(2)\n",
    "sub_pool.starmap_async(sub, [(counter,) for _ in range(2)], error_callback=print_traceback)\n",
    "add_pool.close()\n",
    "sub_pool.close()\n",
    "add_pool.join()\n",
    "sub_pool.join()\n",
    "print(counter.value)"
   ]
  },
  {
   "source": [
    "We have four `add` wokers and two `sub` wokers. Since each worker will change the shared value by +100/-100, we should have 200 as the final result. However, the result is not what we expected because race conditions happened.\n",
    "\n",
    "We wrap the augmented assignment with a `Manager.Lock` in the following code, which gives us the correct output. Apart from `with` statements we used previously, we can also explictly call `acquire()` and `release()` method of `Lock`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Manager, Pool, Value\n",
    "\n",
    "def print_traceback(e):\n",
    "    print(traceback.print_exception(type(e), e, e.__traceback__))\n",
    "\n",
    "def add(counter, counter_lock):\n",
    "    for _ in range(100):\n",
    "        counter_lock.acquire()\n",
    "        counter.value += 1\n",
    "        counter_lock.release()\n",
    "\n",
    "def sub(counter, counter_lock):\n",
    "    for _ in range(100):\n",
    "        counter_lock.acquire()\n",
    "        counter.value -= 1\n",
    "        counter_lock.release()\n",
    "\n",
    "manager = Manager()\n",
    "counter = manager.Value('i', 0)\n",
    "counter_lock = manager.Lock()\n",
    "add_pool = Pool(4)\n",
    "add_pool.starmap_async(add, [(counter, counter_lock) for _ in range(4)], error_callback=print_traceback)\n",
    "sub_pool = Pool(2)\n",
    "sub_pool.starmap_async(sub, [(counter, counter_lock) for _ in range(2)], error_callback=print_traceback)\n",
    "add_pool.close()\n",
    "sub_pool.close()\n",
    "add_pool.join()\n",
    "sub_pool.join()\n",
    "print(counter.value)"
   ]
  }
 ]
}